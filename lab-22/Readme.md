**Lab 22 is where you stop being â€œscared of Terraform stateâ€ and start controlling it.**
This is *exactly* what senior engineers are expected to know.

Iâ€™ll walk you through this **step-by-step**, **safely**, with **intentional breakage**, **why it breaks**, and **how to recover without nuking infra**.

---

# ğŸ§ª Lab 22: Failure Scenarios â€“ Terraform State Debugging

## ğŸ¯ Goal

Gain confidence in **fixing Terraform state issues** without:

* deleting real infrastructure
* re-creating AKS
* panicking ğŸ˜…

---

## ğŸ§  What Terraform State Really Is

Terraform state:

* Maps **Terraform resource addresses** âœ **Real cloud resources**
* Is **NOT** the infrastructure itself
* Is a **source of truth** for Terraform only

If state breaks:

* Infra still exists
* Terraform just *loses track of it*

ğŸ‘‰ Thatâ€™s why **state surgery** exists.

---

## âš ï¸ Safety Rules Before You Start

âœ… Do this in **dev** environment
âŒ Never test state surgery first in prod
âœ… Always take backup

```bash
terraform state pull > state-backup.json
```

(With Terragrunt)

```bash
terragrunt state pull > state-backup.json
```

---

# PART 1ï¸âƒ£ Intentionally Break the State (Safe Way)

We will **remove a resource from state**, but **NOT from Azure**.

### Example resource

AKS node pool:

```hcl
azurerm_kubernetes_cluster_node_pool.user
```

---

### ğŸ”¥ Break the state

```bash
terragrunt state rm azurerm_kubernetes_cluster_node_pool.user
```

ğŸ’¥ Result:

* Node pool still exists in Azure
* Terraform *thinks it doesnâ€™t*

---

### Verify breakage

```bash
terragrunt plan
```

Youâ€™ll see:

```
+ create azurerm_kubernetes_cluster_node_pool.user
```

Terraform wants to **recreate** it â†’ ğŸš¨ danger in prod.

---

## âœ… Congratulations â€” you broke state successfully

This **exact scenario happens in real companies**.

---

# PART 2ï¸âƒ£ Investigate State (Read-Only)

---

## ğŸ” List what Terraform thinks exists

```bash
terragrunt state list
```

Youâ€™ll notice:

* Node pool resource missing
* Everything else intact

---

## ğŸ” Inspect real infra (Azure side)

```bash
az aks nodepool list \
  --cluster-name aks-dev \
  --resource-group rg-dev \
  -o table
```

Node pool is clearly **still there**.

ğŸ‘‰ **State drift confirmed**

---

# PART 3ï¸âƒ£ Fix the Problem (Two Real Paths)

---

## ğŸ›  OPTION 1: Re-import the Resource (Best Practice)

### Find resource ID

```bash
az aks nodepool show \
  --resource-group rg-dev \
  --cluster-name aks-dev \
  --name userpool \
  --query id -o tsv
```

---

### Import back into state

```bash
terragrunt import \
  azurerm_kubernetes_cluster_node_pool.user \
  /subscriptions/.../nodePools/userpool
```

---

### Verify

```bash
terragrunt plan
```

Output:

```
No changes.
```

âœ… State restored
âœ… Infra untouched
âœ… Confidence gained

---

## ğŸ›  OPTION 2: Remove + Let Terraform Recreate (Destructive)

âš ï¸ Only acceptable if:

* resource is disposable
* or environment is dev/test

```bash
terragrunt apply
```

Terraform:

* Deletes node pool
* Recreates it

ğŸš« **Not recommended for prod AKS node pools**

---

# PART 4ï¸âƒ£ When to Use `terraform state rm`

| Scenario                      | Correct Action    |
| ----------------------------- | ----------------- |
| Resource deleted manually     | `state rm`        |
| Terraform address renamed     | `state mv`        |
| Resource exists but unmanaged | `import`          |
| Drift detected                | Investigate first |

---

# PART 5ï¸âƒ£ Common Real-World State Failures

### âŒ Manual Azure Portal Change

Terraform doesnâ€™t know â†’ drift

### âŒ Module refactor

Resource address changed

### âŒ Remote state corruption

Bad migration / backend issue

### âŒ Copy-paste environments

Same resource IDs, wrong state

---

# PART 6ï¸âƒ£ Advanced State Commands (You Should Know)

### Move resource after refactor

```bash
terraform state mv \
  module.old_aks.azurerm_kubernetes_cluster.this \
  module.new_aks.azurerm_kubernetes_cluster.this
```

---

### Show raw state entry

```bash
terraform state show azurerm_kubernetes_cluster.this
```

---

### Replace resource without touching others

```bash
terraform apply -replace="azurerm_kubernetes_cluster_node_pool.user"
```

---

# PART 7ï¸âƒ£ Terragrunt + State Debugging (Important)

Terragrunt:

* Does **not change Terraform state behavior**
* Only **wraps** Terraform

All these work:

```bash
terragrunt state list
terragrunt state rm
terragrunt import
```

---

# âœ… Deliverable Check

âœ” State intentionally broken
âœ” Drift identified
âœ” `state list` used
âœ” `state rm` understood
âœ” State repaired safely

You now **control Terraform**, not the other way around.

---

# ğŸ§  What This Lab Really Teaches

* Terraform state is **recoverable**
* Panic deletes infra â€” knowledge saves it
* Senior engineers **inspect first, act second**
* State surgery is a **skill**, not a hack

---

